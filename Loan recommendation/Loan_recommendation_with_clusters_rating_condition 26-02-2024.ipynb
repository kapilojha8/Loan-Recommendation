{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd13dc5-63cc-48d9-8edf-4b092658e3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dd5b55-5584-485d-8a04-65ecf3e768e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e20dd32e-1530-42f6-bdf9-c3f5806e837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr, rank, countDistinct, count\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder, CrossValidator\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9347be3d-5e8b-40b5-a5f5-91ec804deebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml import Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7feab969-e8a3-4d26-adb0-080556999837",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('loan_recommendation_with_clusters').config(\"spark.driver.memory\", \"15g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "867605ca-18ec-48d8-8109-8871e4118aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://MR-23:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>loan_recommendation_with_clusters</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x195b1161a30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c193e8d5-ed73-4ce1-8c2a-8580263c5921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- AccountID: string (nullable = true)\n",
      " |-- Number_Of_Loans_Granted__c: integer (nullable = true)\n",
      " |-- Num_Of_Loans_Paid__c: integer (nullable = true)\n",
      " |-- Purpose_of_Loan__c: string (nullable = true)\n",
      " |-- Total_Repayments__c: integer (nullable = true)\n",
      " |-- Amount: integer (nullable = true)\n",
      " |-- Term_in_Weeks__c: double (nullable = true)\n",
      " |-- Payment_Frequency__c: string (nullable = true)\n",
      " |-- StageName: string (nullable = true)\n",
      " |-- Applicant Age: integer (nullable = true)\n",
      " |-- summary_income: double (nullable = true)\n",
      " |-- summary_income_cv: double (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- loanId: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- LoanIdFormat: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loans_df = spark.read.csv(\"Loan_Dataset/df_temp_cluster_rating_condition_data.csv\", inferSchema=True, header=True)\n",
    "loans_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66fda6a1-a162-4b31-9076-0a3a230f16de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+-------------------+--------------------+-----+\n",
      "|LoanIdFormat|Amount|Total_Repayments__c|Payment_Frequency__c|count|\n",
      "+------------+------+-------------------+--------------------+-----+\n",
      "|           1|   500|                 10|              Weekly|    3|\n",
      "|           1|   700|                 10|              Weekly|    3|\n",
      "|           1|   800|                 10|              Weekly|    3|\n",
      "|           1|   800|                 10|              Weekly|    3|\n",
      "|           1|   800|                 10|              Weekly|    3|\n",
      "|           1|   800|                 10|              Weekly|    3|\n",
      "|           1|   800|                 10|              Weekly|    3|\n",
      "|           1|   900|                 10|              Weekly|    3|\n",
      "|           1|  1000|                 10|              Weekly|    3|\n",
      "|           1|  1000|                 10|              Weekly|    3|\n",
      "+------------+------+-------------------+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loans_df.select([\"LoanIdFormat\",\"Amount\",\"Total_Repayments__c\",\"Payment_Frequency__c\",\"count\"]).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b17fa619-e0b5-459a-aa9b-1b30dfb9b411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+-----------------+-------------------+--------------------------+--------------------+\n",
      "|summary|            userId|      LoanIdFormat|             count|           Amount|Total_Repayments__c|Number_Of_Loans_Granted__c|Num_Of_Loans_Paid__c|\n",
      "+-------+------------------+------------------+------------------+-----------------+-------------------+--------------------------+--------------------+\n",
      "|  count|            559151|            559151|            559151|           559151|             559151|                    559151|              559151|\n",
      "|   mean|24735.774815747445| 4.527168868516734|1.6699120631099649|823.7755990778877| 7.0393507299459355|        11.901447015206983|   11.85676856519974|\n",
      "| stddev|15283.929730968575|2.7984778294163046|0.8954014280676444|766.2637755312196| 3.9631196080149786|         8.154409123854771|   8.273339043377455|\n",
      "|    min|                 1|                 1|                 0|              100|                  1|                         0|                   3|\n",
      "|    max|             59174|                20|                 8|             5000|                 45|                        73|                  73|\n",
      "+-------+------------------+------------------+------------------+-----------------+-------------------+--------------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loans_df.select([\"userId\",\"LoanIdFormat\",\"count\",\"Amount\",\"Total_Repayments__c\",\"Number_Of_Loans_Granted__c\",\"Num_Of_Loans_Paid__c\"]).describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aff3ab50-da66-4a88-ab6e-64da2d8ec778",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------------\n",
      " Id                         | 0062x00000DsEQcAAN   \n",
      " AccountID                  | 0010K00001ayVHPQA2   \n",
      " Number_Of_Loans_Granted__c | 27                   \n",
      " Num_Of_Loans_Paid__c       | 27                   \n",
      " Purpose_of_Loan__c         | Furniture or Appl... \n",
      " Total_Repayments__c        | 10                   \n",
      " Amount                     | 500                  \n",
      " Term_in_Weeks__c           | 10.143               \n",
      " Payment_Frequency__c       | Weekly               \n",
      " StageName                  | Loan Paid            \n",
      " Applicant Age              | 55                   \n",
      " summary_income             | 2166.67              \n",
      " summary_income_cv          | 5750.7               \n",
      " city                       | Jimboomba            \n",
      " state                      | QLD                  \n",
      " Country                    | Australia            \n",
      " userId                     | 1                    \n",
      " loanId                     | 385865               \n",
      " count                      | 3                    \n",
      " LoanIdFormat               | 1                    \n",
      "-RECORD 1------------------------------------------\n",
      " Id                         | 0062x00000471C0AAI   \n",
      " AccountID                  | 0010K00001ayVHPQA2   \n",
      " Number_Of_Loans_Granted__c | 27                   \n",
      " Num_Of_Loans_Paid__c       | 27                   \n",
      " Purpose_of_Loan__c         | Furniture or Appl... \n",
      " Total_Repayments__c        | 10                   \n",
      " Amount                     | 700                  \n",
      " Term_in_Weeks__c           | 10.0                 \n",
      " Payment_Frequency__c       | Weekly               \n",
      " StageName                  | Loan Paid            \n",
      " Applicant Age              | 55                   \n",
      " summary_income             | 2166.67              \n",
      " summary_income_cv          | 3901.44              \n",
      " city                       | Jimboomba            \n",
      " state                      | QLD                  \n",
      " Country                    | Australia            \n",
      " userId                     | 1                    \n",
      " loanId                     | 96163                \n",
      " count                      | 3                    \n",
      " LoanIdFormat               | 1                    \n",
      "-RECORD 2------------------------------------------\n",
      " Id                         | 0060K00000QSYfLQAX   \n",
      " AccountID                  | 0010K00001ayVHPQA2   \n",
      " Number_Of_Loans_Granted__c | 27                   \n",
      " Num_Of_Loans_Paid__c       | 27                   \n",
      " Purpose_of_Loan__c         | Vehicle Expenses     \n",
      " Total_Repayments__c        | 10                   \n",
      " Amount                     | 800                  \n",
      " Term_in_Weeks__c           | 10.0                 \n",
      " Payment_Frequency__c       | Weekly               \n",
      " StageName                  | Loan Paid            \n",
      " Applicant Age              | 55                   \n",
      " summary_income             | 2166.67              \n",
      " summary_income_cv          | 0.0                  \n",
      " city                       | Jimboomba            \n",
      " state                      | QLD                  \n",
      " Country                    | Australia            \n",
      " userId                     | 1                    \n",
      " loanId                     | 102                  \n",
      " count                      | 3                    \n",
      " LoanIdFormat               | 1                    \n",
      "-RECORD 3------------------------------------------\n",
      " Id                         | 0060K00000SvU4QQAV   \n",
      " AccountID                  | 0010K00001ayVHPQA2   \n",
      " Number_Of_Loans_Granted__c | 27                   \n",
      " Num_Of_Loans_Paid__c       | 27                   \n",
      " Purpose_of_Loan__c         | Furniture or Appl... \n",
      " Total_Repayments__c        | 10                   \n",
      " Amount                     | 800                  \n",
      " Term_in_Weeks__c           | 10.0                 \n",
      " Payment_Frequency__c       | Weekly               \n",
      " StageName                  | Loan Paid            \n",
      " Applicant Age              | 55                   \n",
      " summary_income             | 2166.67              \n",
      " summary_income_cv          | 0.0                  \n",
      " city                       | Jimboomba            \n",
      " state                      | QLD                  \n",
      " Country                    | Australia            \n",
      " userId                     | 1                    \n",
      " loanId                     | 10278                \n",
      " count                      | 3                    \n",
      " LoanIdFormat               | 1                    \n",
      "-RECORD 4------------------------------------------\n",
      " Id                         | 0060K00000S81TeQAJ   \n",
      " AccountID                  | 0010K00001ayVHPQA2   \n",
      " Number_Of_Loans_Granted__c | 27                   \n",
      " Num_Of_Loans_Paid__c       | 27                   \n",
      " Purpose_of_Loan__c         | Vehicle Expenses     \n",
      " Total_Repayments__c        | 10                   \n",
      " Amount                     | 800                  \n",
      " Term_in_Weeks__c           | 10.0                 \n",
      " Payment_Frequency__c       | Weekly               \n",
      " StageName                  | Loan Paid            \n",
      " Applicant Age              | 55                   \n",
      " summary_income             | 2166.67              \n",
      " summary_income_cv          | 0.0                  \n",
      " city                       | Jimboomba            \n",
      " state                      | QLD                  \n",
      " Country                    | Australia            \n",
      " userId                     | 1                    \n",
      " loanId                     | 6480                 \n",
      " count                      | 3                    \n",
      " LoanIdFormat               | 1                    \n",
      "-RECORD 5------------------------------------------\n",
      " Id                         | 0060K00000RVz9FQAT   \n",
      " AccountID                  | 0010K00001ayVHPQA2   \n",
      " Number_Of_Loans_Granted__c | 27                   \n",
      " Num_Of_Loans_Paid__c       | 27                   \n",
      " Purpose_of_Loan__c         | Vehicle Expenses     \n",
      " Total_Repayments__c        | 10                   \n",
      " Amount                     | 800                  \n",
      " Term_in_Weeks__c           | 9.857                \n",
      " Payment_Frequency__c       | Weekly               \n",
      " StageName                  | Loan Paid            \n",
      " Applicant Age              | 55                   \n",
      " summary_income             | 2166.67              \n",
      " summary_income_cv          | 0.0                  \n",
      " city                       | Jimboomba            \n",
      " state                      | QLD                  \n",
      " Country                    | Australia            \n",
      " userId                     | 1                    \n",
      " loanId                     | 4856                 \n",
      " count                      | 3                    \n",
      " LoanIdFormat               | 1                    \n",
      "-RECORD 6------------------------------------------\n",
      " Id                         | 0060K00000RSm5eQAD   \n",
      " AccountID                  | 0010K00001ayVHPQA2   \n",
      " Number_Of_Loans_Granted__c | 27                   \n",
      " Num_Of_Loans_Paid__c       | 27                   \n",
      " Purpose_of_Loan__c         | Repay Existing Debt  \n",
      " Total_Repayments__c        | 10                   \n",
      " Amount                     | 800                  \n",
      " Term_in_Weeks__c           | 10.0                 \n",
      " Payment_Frequency__c       | Weekly               \n",
      " StageName                  | Loan Paid            \n",
      " Applicant Age              | 55                   \n",
      " summary_income             | 2166.67              \n",
      " summary_income_cv          | 0.0                  \n",
      " city                       | Jimboomba            \n",
      " state                      | QLD                  \n",
      " Country                    | Australia            \n",
      " userId                     | 1                    \n",
      " loanId                     | 2664                 \n",
      " count                      | 3                    \n",
      " LoanIdFormat               | 1                    \n",
      "-RECORD 7------------------------------------------\n",
      " Id                         | 0062x000005U1CbAAK   \n",
      " AccountID                  | 0010K00001ayVHPQA2   \n",
      " Number_Of_Loans_Granted__c | 27                   \n",
      " Num_Of_Loans_Paid__c       | 27                   \n",
      " Purpose_of_Loan__c         | Vehicle Expenses     \n",
      " Total_Repayments__c        | 10                   \n",
      " Amount                     | 900                  \n",
      " Term_in_Weeks__c           | 9.857                \n",
      " Payment_Frequency__c       | Weekly               \n",
      " StageName                  | Loan Paid            \n",
      " Applicant Age              | 55                   \n",
      " summary_income             | 2166.67              \n",
      " summary_income_cv          | 3337.99              \n",
      " city                       | Jimboomba            \n",
      " state                      | QLD                  \n",
      " Country                    | Australia            \n",
      " userId                     | 1                    \n",
      " loanId                     | 111498               \n",
      " count                      | 3                    \n",
      " LoanIdFormat               | 1                    \n",
      "-RECORD 8------------------------------------------\n",
      " Id                         | 0060K00000U7781QAB   \n",
      " AccountID                  | 0010K00001ayVHPQA2   \n",
      " Number_Of_Loans_Granted__c | 27                   \n",
      " Num_Of_Loans_Paid__c       | 27                   \n",
      " Purpose_of_Loan__c         | Vehicle Expenses     \n",
      " Total_Repayments__c        | 10                   \n",
      " Amount                     | 1000                 \n",
      " Term_in_Weeks__c           | 10.0                 \n",
      " Payment_Frequency__c       | Weekly               \n",
      " StageName                  | Loan Paid            \n",
      " Applicant Age              | 55                   \n",
      " summary_income             | 2166.67              \n",
      " summary_income_cv          | 0.0                  \n",
      " city                       | Jimboomba            \n",
      " state                      | QLD                  \n",
      " Country                    | Australia            \n",
      " userId                     | 1                    \n",
      " loanId                     | 13633                \n",
      " count                      | 3                    \n",
      " LoanIdFormat               | 1                    \n",
      "-RECORD 9------------------------------------------\n",
      " Id                         | 0060K00000YZwv8QAD   \n",
      " AccountID                  | 0010K00001ayVHPQA2   \n",
      " Number_Of_Loans_Granted__c | 27                   \n",
      " Num_Of_Loans_Paid__c       | 27                   \n",
      " Purpose_of_Loan__c         | Furniture or Appl... \n",
      " Total_Repayments__c        | 10                   \n",
      " Amount                     | 1000                 \n",
      " Term_in_Weeks__c           | 10.0                 \n",
      " Payment_Frequency__c       | Weekly               \n",
      " StageName                  | Loan Paid            \n",
      " Applicant Age              | 55                   \n",
      " summary_income             | 2166.67              \n",
      " summary_income_cv          | 3074.46              \n",
      " city                       | Jimboomba            \n",
      " state                      | QLD                  \n",
      " Country                    | Australia            \n",
      " userId                     | 1                    \n",
      " loanId                     | 52404                \n",
      " count                      | 3                    \n",
      " LoanIdFormat               | 1                    \n",
      "-RECORD 10-----------------------------------------\n",
      " Id                         | 0062x0000070YprAAE   \n",
      " AccountID                  | 0010K00001ayVHjQAM   \n",
      " Number_Of_Loans_Granted__c | 15                   \n",
      " Num_Of_Loans_Paid__c       | 15                   \n",
      " Purpose_of_Loan__c         | Vehicle Expenses     \n",
      " Total_Repayments__c        | 10                   \n",
      " Amount                     | 300                  \n",
      " Term_in_Weeks__c           | 9.857                \n",
      " Payment_Frequency__c       | Weekly               \n",
      " StageName                  | Loan Paid            \n",
      " Applicant Age              | 36                   \n",
      " summary_income             | 6066.67              \n",
      " summary_income_cv          | 5176.26              \n",
      " city                       | Brisbane             \n",
      " state                      | QLD                  \n",
      " Country                    | Australia            \n",
      " userId                     | 2                    \n",
      " loanId                     | 133877               \n",
      " count                      | 2                    \n",
      " LoanIdFormat               | 1                    \n",
      "-RECORD 11-----------------------------------------\n",
      " Id                         | 0062x00000732K5AAI   \n",
      " AccountID                  | 0010K00001ayVHjQAM   \n",
      " Number_Of_Loans_Granted__c | 15                   \n",
      " Num_Of_Loans_Paid__c       | 15                   \n",
      " Purpose_of_Loan__c         | Home Maintenance ... \n",
      " Total_Repayments__c        | 10                   \n",
      " Amount                     | 350                  \n",
      " Term_in_Weeks__c           | 10.0                 \n",
      " Payment_Frequency__c       | Weekly               \n",
      " StageName                  | Loan Paid            \n",
      " Applicant Age              | 36                   \n",
      " summary_income             | 6066.67              \n",
      " summary_income_cv          | 5056.75              \n",
      " city                       | Brisbane             \n",
      " state                      | QLD                  \n",
      " Country                    | Australia            \n",
      " userId                     | 2                    \n",
      " loanId                     | 139276               \n",
      " count                      | 2                    \n",
      " LoanIdFormat               | 1                    \n",
      "-RECORD 12-----------------------------------------\n",
      " Id                         | 0062x000009032NAAQ   \n",
      " AccountID                  | 0010K00001ayVHjQAM   \n",
      " Number_Of_Loans_Granted__c | 15                   \n",
      " Num_Of_Loans_Paid__c       | 15                   \n",
      " Purpose_of_Loan__c         | Vehicle Expenses     \n",
      " Total_Repayments__c        | 10                   \n",
      " Amount                     | 400                  \n",
      " Term_in_Weeks__c           | 9.857                \n",
      " Payment_Frequency__c       | Weekly               \n",
      " StageName                  | Loan Paid            \n",
      " Applicant Age              | 36                   \n",
      " summary_income             | 6066.67              \n",
      " summary_income_cv          | 4921.72              \n",
      " city                       | Brisbane             \n",
      " state                      | QLD                  \n",
      " Country                    | Australia            \n",
      " userId                     | 2                    \n",
      " loanId                     | 168095               \n",
      " count                      | 2                    \n",
      " LoanIdFormat               | 1                    \n",
      "-RECORD 13-----------------------------------------\n",
      " Id                         | 0060K00000RVsZZQA1   \n",
      " AccountID                  | 0010K00001ayVHjQAM   \n",
      " Number_Of_Loans_Granted__c | 15                   \n",
      " Num_Of_Loans_Paid__c       | 15                   \n",
      " Purpose_of_Loan__c         | Furniture or Appl... \n",
      " Total_Repayments__c        | 10                   \n",
      " Amount                     | 600                  \n",
      " Term_in_Weeks__c           | 10.0                 \n",
      " Payment_Frequency__c       | Weekly               \n",
      " StageName                  | Loan Paid            \n",
      " Applicant Age              | 36                   \n",
      " summary_income             | 6066.67              \n",
      " summary_income_cv          | 0.0                  \n",
      " city                       | Brisbane             \n",
      " state                      | QLD                  \n",
      " Country                    | Australia            \n",
      " userId                     | 2                    \n",
      " loanId                     | 4760                 \n",
      " count                      | 2                    \n",
      " LoanIdFormat               | 1                    \n",
      "-RECORD 14-----------------------------------------\n",
      " Id                         | 0062x00000BHhsjAAD   \n",
      " AccountID                  | 0010K00001ayVHjQAM   \n",
      " Number_Of_Loans_Granted__c | 15                   \n",
      " Num_Of_Loans_Paid__c       | 15                   \n",
      " Purpose_of_Loan__c         | Vehicle Expenses     \n",
      " Total_Repayments__c        | 14                   \n",
      " Amount                     | 600                  \n",
      " Term_in_Weeks__c           | 14.0                 \n",
      " Payment_Frequency__c       | Weekly               \n",
      " StageName                  | Loan Paid            \n",
      " Applicant Age              | 36                   \n",
      " summary_income             | 6066.67              \n",
      " summary_income_cv          | 4245.5               \n",
      " city                       | Brisbane             \n",
      " state                      | QLD                  \n",
      " Country                    | Australia            \n",
      " userId                     | 2                    \n",
      " loanId                     | 286173               \n",
      " count                      | 2                    \n",
      " LoanIdFormat               | 1                    \n",
      "-RECORD 15-----------------------------------------\n",
      " Id                         | 0062x00000AdqkVAAR   \n",
      " AccountID                  | 0010K00001ayVHjQAM   \n",
      " Number_Of_Loans_Granted__c | 15                   \n",
      " Num_Of_Loans_Paid__c       | 15                   \n",
      " Purpose_of_Loan__c         | Home Maintenance ... \n",
      " Total_Repayments__c        | 14                   \n",
      " Amount                     | 600                  \n",
      " Term_in_Weeks__c           | 14.0                 \n",
      " Payment_Frequency__c       | Weekly               \n",
      " StageName                  | Loan Paid            \n",
      " Applicant Age              | 36                   \n",
      " summary_income             | 6066.67              \n",
      " summary_income_cv          | 5219.93              \n",
      " city                       | Brisbane             \n",
      " state                      | QLD                  \n",
      " Country                    | Australia            \n",
      " userId                     | 2                    \n",
      " loanId                     | 243982               \n",
      " count                      | 2                    \n",
      " LoanIdFormat               | 1                    \n",
      "-RECORD 16-----------------------------------------\n",
      " Id                         | 0062x00000A8CaFAAV   \n",
      " AccountID                  | 0010K00001ayVHjQAM   \n",
      " Number_Of_Loans_Granted__c | 15                   \n",
      " Num_Of_Loans_Paid__c       | 15                   \n",
      " Purpose_of_Loan__c         | Vehicle Expenses     \n",
      " Total_Repayments__c        | 14                   \n",
      " Amount                     | 600                  \n",
      " Term_in_Weeks__c           | 13.714               \n",
      " Payment_Frequency__c       | Weekly               \n",
      " StageName                  | Loan Paid            \n",
      " Applicant Age              | 36                   \n",
      " summary_income             | 6066.67              \n",
      " summary_income_cv          | 5062.59              \n",
      " city                       | Brisbane             \n",
      " state                      | QLD                  \n",
      " Country                    | Australia            \n",
      " userId                     | 2                    \n",
      " loanId                     | 212486               \n",
      " count                      | 2                    \n",
      " LoanIdFormat               | 1                    \n",
      "-RECORD 17-----------------------------------------\n",
      " Id                         | 0062x000009Fjw5AAC   \n",
      " AccountID                  | 0010K00001ayVHjQAM   \n",
      " Number_Of_Loans_Granted__c | 15                   \n",
      " Num_Of_Loans_Paid__c       | 15                   \n",
      " Purpose_of_Loan__c         | Home Maintenance ... \n",
      " Total_Repayments__c        | 14                   \n",
      " Amount                     | 600                  \n",
      " Term_in_Weeks__c           | 13.857               \n",
      " Payment_Frequency__c       | Weekly               \n",
      " StageName                  | Loan Paid            \n",
      " Applicant Age              | 36                   \n",
      " summary_income             | 6066.67              \n",
      " summary_income_cv          | 4720.26              \n",
      " city                       | Brisbane             \n",
      " state                      | QLD                  \n",
      " Country                    | Australia            \n",
      " userId                     | 2                    \n",
      " loanId                     | 185505               \n",
      " count                      | 2                    \n",
      " LoanIdFormat               | 1                    \n",
      "-RECORD 18-----------------------------------------\n",
      " Id                         | 0060K00000S7sobQAB   \n",
      " AccountID                  | 0010K00001ayVHjQAM   \n",
      " Number_Of_Loans_Granted__c | 15                   \n",
      " Num_Of_Loans_Paid__c       | 15                   \n",
      " Purpose_of_Loan__c         | Furniture or Appl... \n",
      " Total_Repayments__c        | 10                   \n",
      " Amount                     | 600                  \n",
      " Term_in_Weeks__c           | 10.143               \n",
      " Payment_Frequency__c       | Weekly               \n",
      " StageName                  | Loan Paid            \n",
      " Applicant Age              | 36                   \n",
      " summary_income             | 6066.67              \n",
      " summary_income_cv          | 0.0                  \n",
      " city                       | Brisbane             \n",
      " state                      | QLD                  \n",
      " Country                    | Australia            \n",
      " userId                     | 2                    \n",
      " loanId                     | 6324                 \n",
      " count                      | 2                    \n",
      " LoanIdFormat               | 1                    \n",
      "-RECORD 19-----------------------------------------\n",
      " Id                         | 0062x00000BBnydAAD   \n",
      " AccountID                  | 0010K00001ayVHjQAM   \n",
      " Number_Of_Loans_Granted__c | 15                   \n",
      " Num_Of_Loans_Paid__c       | 15                   \n",
      " Purpose_of_Loan__c         | Vehicle Expenses     \n",
      " Total_Repayments__c        | 10                   \n",
      " Amount                     | 1000                 \n",
      " Term_in_Weeks__c           | 10.714               \n",
      " Payment_Frequency__c       | Weekly               \n",
      " StageName                  | Loan Paid            \n",
      " Applicant Age              | 36                   \n",
      " summary_income             | 6066.67              \n",
      " summary_income_cv          | 4294.75              \n",
      " city                       | Brisbane             \n",
      " state                      | QLD                  \n",
      " Country                    | Australia            \n",
      " userId                     | 2                    \n",
      " loanId                     | 282397               \n",
      " count                      | 2                    \n",
      " LoanIdFormat               | 1                    \n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loans_df.show(vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "879b0ed5-5a6a-4f4f-a02a-1ef3be15bd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data  = loans_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e20cc21-d8fc-478f-ae00-442e698e0c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist_data['count'].hist()\n",
    "plt.xlabel(\"count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(f\"Histogram of count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7ad932-9155-41cc-b30b-97711374a062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bb8db5-e183-44d9-b3f7-b9b3647bfb14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93606394-8fb4-4d30-8235-c8e1cdb15a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique loanId_format: 20\n",
      "Number of unique Loan Id: 407389\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique items\n",
    "num_unique_loan_id_format = loans_df.select('LoanIdFormat').distinct().count()\n",
    "print(f\"Number of unique loanId_format: {num_unique_loan_id_format}\")\n",
    "\n",
    "# Count the number of unique users\n",
    "num_unique_id = loans_df.select('Id').distinct().count()\n",
    "print(f\"Number of unique Loan Id: {num_unique_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa9f871b-ee01-470a-af88-09d50dc228cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 59158\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique items\n",
    "tmp = loans_df.select('userId').distinct().count()\n",
    "print(f\"Number of unique users: {tmp}\")\n",
    "\n",
    "# Count the number of unique users\n",
    "# tmp = ratings_df.select('movieId').distinct().count()\n",
    "# print(f\"Number of unique movies: {tmp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18f5bc8b-ee99-490a-89e0-8a319deb255f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|    1|\n",
      "|    6|\n",
      "|    3|\n",
      "|    5|\n",
      "|    4|\n",
      "|    8|\n",
      "|    7|\n",
      "|    2|\n",
      "|    0|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# distinct values of the rating\n",
    "loans_df.select(\"count\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ad89af-06f7-4fac-b6bb-9d0ec842ed04",
   "metadata": {},
   "source": [
    "========================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea6197c-53b9-4c06-a20d-1e1f2233d371",
   "metadata": {},
   "source": [
    "Converting the dataset into train test and validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25b7a938-17f5-460f-a3bf-78ebd6628477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+------+\n",
      "|LoanIdFormat|count|Amount|\n",
      "+------------+-----+------+\n",
      "|           1|    3|   500|\n",
      "|           1|    3|   700|\n",
      "|           1|    3|   800|\n",
      "|           1|    3|   800|\n",
      "|           1|    3|   800|\n",
      "|           1|    3|   800|\n",
      "|           1|    3|   800|\n",
      "|           1|    3|   900|\n",
      "|           1|    3|  1000|\n",
      "|           1|    3|  1000|\n",
      "+------------+-----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loans_df.select([\"LoanIdFormat\",\"count\",\"Amount\"]).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "471dc8a3-2474-41c2-a4c2-d3f09756df0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Id: string, AccountID: string, Number_Of_Loans_Granted__c: int, Num_Of_Loans_Paid__c: int, Purpose_of_Loan__c: string, Total_Repayments__c: int, Amount: int, Term_in_Weeks__c: double, Payment_Frequency__c: string, StageName: string, Applicant Age: int, summary_income: double, summary_income_cv: double, city: string, state: string, Country: string, userId: int, loanId: int, count: int, LoanIdFormat: int]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, validation = loans_df.randomSplit([0.8, 0.2])\n",
    "# train, validation, test = loans_df.randomSplit([0.8, 0.1, 0.1])\n",
    "# # cache data\n",
    "train.cache()\n",
    "validation.cache()\n",
    "# test.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2ad213d-bf88-4d40-b43e-609a301116fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------------+-----+------+-------------------+\n",
      "|userId|loanId|LoanIdFormat|count|Amount|Total_Repayments__c|\n",
      "+------+------+------------+-----+------+-------------------+\n",
      "|   130|     6|           1|    3|   400|                 10|\n",
      "| 25117|    33|           1|    3|   650|                 10|\n",
      "| 23722|    52|           1|    1|   800|                 10|\n",
      "| 25097|    90|           1|    2|   200|                 10|\n",
      "|   186|    99|           1|    1|   350|                 10|\n",
      "| 25245|   190|           1|    1|   850|                 10|\n",
      "|    76|   231|           1|    1|   400|                 10|\n",
      "| 25043|   253|           1|    2|   400|                 10|\n",
      "| 24094|   254|           1|    1|  1000|                 10|\n",
      "| 24945|   286|           1|    1|   500|                 10|\n",
      "| 24975|   289|           1|    2|   200|                 10|\n",
      "| 24267|   291|           1|    3|   200|                 10|\n",
      "| 25279|   323|           1|    1|   500|                 10|\n",
      "| 23319|   327|           1|    2|   250|                 10|\n",
      "| 23435|   364|           1|    2|   250|                 10|\n",
      "| 24703|   370|           1|    4|   900|                 10|\n",
      "|   205|   375|           1|    1|   300|                 10|\n",
      "| 25273|   387|           1|    2|   250|                 10|\n",
      "| 23813|   398|           1|    1|   200|                 10|\n",
      "|   232|   414|           1|    2|   500|                 10|\n",
      "+------+------+------------+-----+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validation.select([\"userId\",\"loanId\",\"LoanIdFormat\",\"count\",\"Amount\",\"Total_Repayments__c\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4ec2ccf-e2df-4169-82d1-84b24e8cdf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- AccountID: string (nullable = true)\n",
      " |-- Number_Of_Loans_Granted__c: integer (nullable = true)\n",
      " |-- Num_Of_Loans_Paid__c: integer (nullable = true)\n",
      " |-- Purpose_of_Loan__c: string (nullable = true)\n",
      " |-- Total_Repayments__c: integer (nullable = true)\n",
      " |-- Amount: integer (nullable = true)\n",
      " |-- Term_in_Weeks__c: double (nullable = true)\n",
      " |-- Payment_Frequency__c: string (nullable = true)\n",
      " |-- StageName: string (nullable = true)\n",
      " |-- Applicant Age: integer (nullable = true)\n",
      " |-- summary_income: double (nullable = true)\n",
      " |-- summary_income_cv: double (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- loanId: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- LoanIdFormat: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loans_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2226eb6-5980-4249-bd83-5f3b6862faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ALS(train_data, validation_data, num_iters, reg_param, ranks):\n",
    "    \"\"\"\n",
    "    Grid Search Function to select the best model based on RMSE of hold-out data\n",
    "    \"\"\"\n",
    "    # initial\n",
    "    min_error = float('inf')\n",
    "    best_rank = -1\n",
    "    best_regularization = 0\n",
    "    best_model = None\n",
    "    for rank in ranks:\n",
    "        for reg in reg_param:\n",
    "            # Train the model using the training data\n",
    "            als_model = ALS(maxIter=num_iters,regParam=reg, rank=rank,\n",
    "                                        userCol='userId', itemCol='LoanIdFormat', ratingCol='count', seed=99,\n",
    "                           coldStartStrategy=\"drop\",nonnegative=True)\n",
    "            model = als_model.fit(train_data)\n",
    "            \n",
    "            # Generate predictions on the test data\n",
    "            predictions = model.transform(validation_data)\n",
    "            predictions = predictions.withColumn(\"prediction\", expr(\"CASE WHEN prediction < 0 THEN 0 WHEN prediction > 9 THEN 9 ELSE prediction END\"))\n",
    "            \n",
    "            evaluator = RegressionEvaluator(metricName='rmse', labelCol='count', predictionCol='prediction')\n",
    "            error = evaluator.evaluate(predictions)\n",
    "            \n",
    "            print('{} latent factors and regularization = {}: validation RMSE is {}'.format(rank, reg, error))\n",
    "            if error < min_error:\n",
    "                min_error = error\n",
    "                best_rank = rank\n",
    "                best_regularization = reg\n",
    "                best_model = model\n",
    "    print('\\nThe best model has {} latent factors and regularization = {}'.format(best_rank, best_regularization))\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb8832fe-fe68-4372-9d4d-294633e187b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 latent factors and regularization = 0.001: validation RMSE is 0.020444812351840813\n",
      "8 latent factors and regularization = 0.01: validation RMSE is 0.025620431301841107\n",
      "8 latent factors and regularization = 0.05: validation RMSE is 0.08053144305623325\n",
      "8 latent factors and regularization = 0.1: validation RMSE is 0.10213915589542055\n",
      "8 latent factors and regularization = 0.2: validation RMSE is 0.19814911852343314\n",
      "10 latent factors and regularization = 0.001: validation RMSE is 0.03799510096152451\n",
      "10 latent factors and regularization = 0.01: validation RMSE is 0.055210625986972184\n",
      "10 latent factors and regularization = 0.05: validation RMSE is 0.07669887253088171\n",
      "10 latent factors and regularization = 0.1: validation RMSE is 0.09638429111410064\n",
      "10 latent factors and regularization = 0.2: validation RMSE is 0.19804733602596913\n",
      "20 latent factors and regularization = 0.001: validation RMSE is 0.10375543458238233\n",
      "20 latent factors and regularization = 0.01: validation RMSE is 0.03498082529906885\n",
      "20 latent factors and regularization = 0.05: validation RMSE is 0.08803085299239126\n",
      "20 latent factors and regularization = 0.1: validation RMSE is 0.10380119556929465\n",
      "20 latent factors and regularization = 0.2: validation RMSE is 0.1981514924089491\n",
      "40 latent factors and regularization = 0.001: validation RMSE is 0.10572718918144895\n",
      "40 latent factors and regularization = 0.01: validation RMSE is 0.051679104358536836\n",
      "40 latent factors and regularization = 0.05: validation RMSE is 0.09203430594445665\n",
      "40 latent factors and regularization = 0.1: validation RMSE is 0.11022480236840308\n",
      "40 latent factors and regularization = 0.2: validation RMSE is 0.19823906236518749\n",
      "60 latent factors and regularization = 0.001: validation RMSE is 0.12123486986877394\n",
      "60 latent factors and regularization = 0.01: validation RMSE is 0.050658593573788574\n",
      "60 latent factors and regularization = 0.05: validation RMSE is 0.09153354661117928\n",
      "60 latent factors and regularization = 0.1: validation RMSE is 0.10861445000667698\n",
      "60 latent factors and regularization = 0.2: validation RMSE is 0.19814093173825947\n",
      "\n",
      "The best model has 8 latent factors and regularization = 0.001\n",
      "Total Runtime: 391.55 seconds\n"
     ]
    }
   ],
   "source": [
    "# hyper-param config\n",
    "num_iterations = 10\n",
    "ranks = [8, 10, 20, 40, 60]\n",
    "reg_params = [0.001, 0.01, 0.05, 0.1, 0.2]\n",
    "\n",
    "# grid search and select best model\n",
    "start_time = time.time()\n",
    "final_model = train_ALS(train, validation, num_iterations, reg_params, ranks)\n",
    "\n",
    "print ('Total Runtime: {:.2f} seconds'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7cf3c57-11f2-46bd-b434-1cebf52a0c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD :  40 latent factors and regularization = 0.001\n",
    "#NEW: The best model has 8 latent factors and regularization = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ea77f2-852c-4fb9-8523-f8c98386655c",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57ba7905-f3e0-4a23-8b3d-0c41ffa5d0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = final_model.transform(validation)\n",
    "# predictions = predictions.withColumn(\"prediction\", expr(\"CASE WHEN prediction < 0 THEN 0 WHEN prediction > 9 THEN 9 ELSE prediction END\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd93785-db30-4571-b897-8ccf3d28e6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e28740c-bd7f-4213-986a-04b0b8453f48",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# Evaluate the model using Root Mean Squared Error (RMSE)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) = \" + str(rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6126443-493a-4f43-9c2c-a3ce31b2d77a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3582bb9e-34ae-4cf5-a0ce-9f09954e4095",
   "metadata": {},
   "outputs": [],
   "source": [
    "root\n",
    " |-- Id: string (nullable = true)\n",
    " |-- AccountID: string (nullable = true)\n",
    " |-- Number_Of_Loans_Granted__c: integer (nullable = true)\n",
    " |-- Num_Of_Loans_Paid__c: integer (nullable = true)\n",
    " |-- Purpose_of_Loan__c: string (nullable = true)\n",
    " |-- Total_Repayments__c: integer (nullable = true)\n",
    " |-- Amount: integer (nullable = true)\n",
    " |-- Term_in_Weeks__c: double (nullable = true)\n",
    " |-- Payment_Frequency__c: string (nullable = true)\n",
    " |-- StageName: string (nullable = true)\n",
    " |-- Applicant Age: integer (nullable = true)\n",
    " |-- summary_income: double (nullable = true)\n",
    " |-- summary_income_cv: double (nullable = true)\n",
    " |-- city: string (nullable = true)\n",
    " |-- state: string (nullable = true)\n",
    " |-- Country: string (nullable = true)\n",
    " |-- userId: integer (nullable = true)\n",
    " |-- loanId: integer (nullable = true)\n",
    " |-- count: integer (nullable = true)\n",
    " |-- LoanIdFormat: integer (nullable = true)\n",
    " |-- prediction: float (nullable = false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "efc1f24f-40d6-452b-a727-dd925239dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "# Assuming 'features' is an array column containing floats\n",
    "assembler = VectorAssembler(inputCols=[\"userId\", \"loanId\", \"count\", \"LoanIdFormat\"], outputCol=\"features_vector\")\n",
    "df_assembled = assembler.transform(loans_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a4198ca2-846d-4140-a4c4-d99e833ddc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Id: string, AccountID: string, Number_Of_Loans_Granted__c: int, Num_Of_Loans_Paid__c: int, Purpose_of_Loan__c: string, Total_Repayments__c: int, Amount: int, Term_in_Weeks__c: double, Payment_Frequency__c: string, StageName: string, Applicant Age: int, summary_income: double, summary_income_cv: double, city: string, state: string, Country: string, userId: int, loanId: int, count: int, LoanIdFormat: int, features_vector: vector]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_assembled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7c0d093f-b72e-40d8-bf51-e5599c31a680",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: Input type must be struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but got int.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m user_normalizer \u001b[38;5;241m=\u001b[39m Normalizer(inputCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muserId\u001b[39m\u001b[38;5;124m\"\u001b[39m , outputCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalized_features\u001b[39m\u001b[38;5;124m\"\u001b[39m, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.0\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m user_normalized \u001b[38;5;241m=\u001b[39m \u001b[43muser_normalizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_assembled\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\ml\\base.py:262\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_transform(dataset)\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be a param map but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\ml\\wrapper.py:398\u001b[0m, in \u001b[0;36mJavaTransformer._transform\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[1;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m, dataset\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: requirement failed: Input type must be struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but got int."
     ]
    }
   ],
   "source": [
    "user_normalizer = Normalizer(inputCol=\"userId\" , outputCol=\"normalized_features\", p=2.0)\n",
    "user_normalized = user_normalizer.transform(df_assembled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ad44df4-9709-4010-95b5-808e6484b92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, features: array<float>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame[Id: string, AccountID: string, Number_Of_Loans_Granted__c: int, Num_Of_Loans_Paid__c: int, Purpose_of_Loan__c: string,\n",
    "Total_Repayments__c: int, Amount: int, Term_in_Weeks__c: double, Payment_Frequency__c: string, StageName: string, Applicant Age:\n",
    "int, summary_income: double, summary_income_cv: double, city: string, state: string, Country: string, userId: int, loanId: int, \n",
    "count: int, LoanIdFormat: int, features_vector: vector]\n",
    "Selection deleted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ee7803be-acd4-462c-abb4-99ecc09b4e29",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o3480.withColumn.\n: java.lang.RuntimeException: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:735)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:270)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:286)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:978)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:660)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788)\r\n\tat org.apache.spark.sql.catalyst.catalog.InMemoryCatalog.liftedTree1$1(InMemoryCatalog.scala:122)\r\n\tat org.apache.spark.sql.catalyst.catalog.InMemoryCatalog.createDatabase(InMemoryCatalog.scala:119)\r\n\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:159)\r\n\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\r\n\tat org.apache.spark.sql.internal.BaseSessionStateBuilder.$anonfun$catalog$1(BaseSessionStateBuilder.scala:154)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isPersistentFunction(SessionCatalog.scala:1579)\r\n\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.functionExists(V2SessionCatalog.scala:367)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions$$anonfun$apply$20.applyOrElse(Analyzer.scala:2009)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions$$anonfun$apply$20.applyOrElse(Analyzer.scala:2000)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$3(TreeNode.scala:466)\r\n\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\r\n\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\r\n\tat org.apache.spark.sql.catalyst.expressions.UnaryExpression.mapChildren(Expression.scala:533)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:466)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$transformExpressionsDownWithPruning$1(QueryPlan.scala:167)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$1(QueryPlan.scala:208)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:208)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:219)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$3(QueryPlan.scala:224)\r\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\r\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\r\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:224)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$4(QueryPlan.scala:229)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:304)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:229)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsDownWithPruning(QueryPlan.scala:167)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsWithPruning(QueryPlan.scala:138)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveExpressionsWithPruning$1.applyOrElse(AnalysisHelper.scala:245)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveExpressionsWithPruning$1.applyOrElse(AnalysisHelper.scala:244)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$2(AnalysisHelper.scala:170)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:170)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning(AnalysisHelper.scala:99)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning$(AnalysisHelper.scala:96)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveExpressionsWithPruning(AnalysisHelper.scala:244)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveExpressionsWithPruning$(AnalysisHelper.scala:242)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveExpressionsWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions$.apply(Analyzer.scala:2000)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions$.apply(Analyzer.scala:1996)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\r\n\tat scala.collection.IndexedSeqOptimized.foldLeft(IndexedSeqOptimized.scala:60)\r\n\tat scala.collection.IndexedSeqOptimized.foldLeft$(IndexedSeqOptimized.scala:68)\r\n\tat scala.collection.mutable.WrappedArray.foldLeft(WrappedArray.scala:38)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\r\n\tat scala.collection.immutable.List.foreach(List.scala:431)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\r\n\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\r\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\r\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\r\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$1(Dataset.scala:91)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:89)\r\n\tat org.apache.spark.sql.Dataset.withPlan(Dataset.scala:4363)\r\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1541)\r\n\tat org.apache.spark.sql.Dataset.withColumns(Dataset.scala:2782)\r\n\tat org.apache.spark.sql.Dataset.withColumn(Dataset.scala:2721)\r\n\tat sun.reflect.GeneratedMethodAccessor143.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:547)\r\n\tat org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:568)\r\n\tat org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:591)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:688)\r\n\tat org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDurationHelper(Configuration.java:1907)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1867)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1840)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)\r\n\tat org.apache.hadoop.util.ShutdownHookManager$HookEntry.<init>(ShutdownHookManager.java:207)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.addShutdownHook(ShutdownHookManager.java:304)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.install(ShutdownHookManager.scala:181)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks$lzycompute(ShutdownHookManager.scala:50)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks(ShutdownHookManager.scala:48)\r\n\tat org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<init>(ShutdownHookManager.scala:58)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<clinit>(ShutdownHookManager.scala)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:242)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir(SparkFileUtils.scala:103)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir$(SparkFileUtils.scala:102)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:94)\r\n\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:372)\r\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:964)\r\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)\r\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)\r\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nCaused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:467)\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:438)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:515)\r\n\t... 25 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m user_features \u001b[38;5;241m=\u001b[39m loans_df\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoanIdFormat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muserId\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mwithColumnRenamed(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m user_similarity \u001b[38;5;241m=\u001b[39m user_features\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcrossJoin(user_features\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu2\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m----> 7\u001b[0m user_similarity \u001b[38;5;241m=\u001b[39m \u001b[43muser_similarity\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcosine_similarity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m   \u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdot(u1.normalized_features, u2.normalized_features)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:5170\u001b[0m, in \u001b[0;36mDataFrame.withColumn\u001b[1;34m(self, colName, col)\u001b[0m\n\u001b[0;32m   5165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, Column):\n\u001b[0;32m   5166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m   5167\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_COLUMN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5168\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(col)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m   5169\u001b[0m     )\n\u001b[1;32m-> 5170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o3480.withColumn.\n: java.lang.RuntimeException: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:735)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:270)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:286)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:978)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:660)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788)\r\n\tat org.apache.spark.sql.catalyst.catalog.InMemoryCatalog.liftedTree1$1(InMemoryCatalog.scala:122)\r\n\tat org.apache.spark.sql.catalyst.catalog.InMemoryCatalog.createDatabase(InMemoryCatalog.scala:119)\r\n\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:159)\r\n\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\r\n\tat org.apache.spark.sql.internal.BaseSessionStateBuilder.$anonfun$catalog$1(BaseSessionStateBuilder.scala:154)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isPersistentFunction(SessionCatalog.scala:1579)\r\n\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.functionExists(V2SessionCatalog.scala:367)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions$$anonfun$apply$20.applyOrElse(Analyzer.scala:2009)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions$$anonfun$apply$20.applyOrElse(Analyzer.scala:2000)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$3(TreeNode.scala:466)\r\n\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\r\n\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\r\n\tat org.apache.spark.sql.catalyst.expressions.UnaryExpression.mapChildren(Expression.scala:533)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:466)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$transformExpressionsDownWithPruning$1(QueryPlan.scala:167)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$1(QueryPlan.scala:208)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:208)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:219)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$3(QueryPlan.scala:224)\r\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\r\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\r\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:224)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$4(QueryPlan.scala:229)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:304)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:229)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsDownWithPruning(QueryPlan.scala:167)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsWithPruning(QueryPlan.scala:138)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveExpressionsWithPruning$1.applyOrElse(AnalysisHelper.scala:245)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveExpressionsWithPruning$1.applyOrElse(AnalysisHelper.scala:244)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$2(AnalysisHelper.scala:170)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:170)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning(AnalysisHelper.scala:99)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning$(AnalysisHelper.scala:96)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveExpressionsWithPruning(AnalysisHelper.scala:244)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveExpressionsWithPruning$(AnalysisHelper.scala:242)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveExpressionsWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions$.apply(Analyzer.scala:2000)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions$.apply(Analyzer.scala:1996)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\r\n\tat scala.collection.IndexedSeqOptimized.foldLeft(IndexedSeqOptimized.scala:60)\r\n\tat scala.collection.IndexedSeqOptimized.foldLeft$(IndexedSeqOptimized.scala:68)\r\n\tat scala.collection.mutable.WrappedArray.foldLeft(WrappedArray.scala:38)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\r\n\tat scala.collection.immutable.List.foreach(List.scala:431)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\r\n\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\r\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\r\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\r\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$1(Dataset.scala:91)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:89)\r\n\tat org.apache.spark.sql.Dataset.withPlan(Dataset.scala:4363)\r\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1541)\r\n\tat org.apache.spark.sql.Dataset.withColumns(Dataset.scala:2782)\r\n\tat org.apache.spark.sql.Dataset.withColumn(Dataset.scala:2721)\r\n\tat sun.reflect.GeneratedMethodAccessor143.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:547)\r\n\tat org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:568)\r\n\tat org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:591)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:688)\r\n\tat org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDurationHelper(Configuration.java:1907)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1867)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1840)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)\r\n\tat org.apache.hadoop.util.ShutdownHookManager$HookEntry.<init>(ShutdownHookManager.java:207)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.addShutdownHook(ShutdownHookManager.java:304)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.install(ShutdownHookManager.scala:181)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks$lzycompute(ShutdownHookManager.scala:50)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks(ShutdownHookManager.scala:48)\r\n\tat org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<init>(ShutdownHookManager.scala:58)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<clinit>(ShutdownHookManager.scala)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:242)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir(SparkFileUtils.scala:103)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir$(SparkFileUtils.scala:102)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:94)\r\n\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:372)\r\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:964)\r\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)\r\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)\r\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nCaused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:467)\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:438)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:515)\r\n\t... 25 more\r\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# Calculate cosine similarity between users using Normalizer and dot product\n",
    "\n",
    "user_features = loans_df.select(\"LoanIdFormat\", \"userId\").withColumnRenamed(\"id\", \"user_id\")\n",
    " \n",
    "user_similarity = user_features.alias(\"u1\").crossJoin(user_features.alias(\"u2\"))\n",
    " \n",
    "user_similarity = user_similarity.withColumn(\n",
    "    \"cosine_similarity\",\n",
    "   expr(\"dot(u1.normalized_features, u2.normalized_features)\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3b28c0d6-5068-49fa-906e-1b2d8ba24fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centered cosine similarity\n",
    "avg_rating = loans_df.select(mean(\"count\")).collect()[0][0]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "abc25076-a299-4195-9cd4-dc375335450b",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o3480.withColumn.\n: java.lang.RuntimeException: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:735)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:270)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:286)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:978)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:660)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788)\r\n\tat org.apache.spark.sql.catalyst.catalog.InMemoryCatalog.liftedTree1$1(InMemoryCatalog.scala:122)\r\n\tat org.apache.spark.sql.catalyst.catalog.InMemoryCatalog.createDatabase(InMemoryCatalog.scala:119)\r\n\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:159)\r\n\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\r\n\tat org.apache.spark.sql.internal.BaseSessionStateBuilder.$anonfun$catalog$1(BaseSessionStateBuilder.scala:154)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isPersistentFunction(SessionCatalog.scala:1579)\r\n\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.functionExists(V2SessionCatalog.scala:367)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions$$anonfun$apply$20.applyOrElse(Analyzer.scala:2009)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions$$anonfun$apply$20.applyOrElse(Analyzer.scala:2000)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$3(TreeNode.scala:466)\r\n\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\r\n\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\r\n\tat org.apache.spark.sql.catalyst.expressions.BinaryExpression.mapChildren(Expression.scala:653)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:466)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$3(TreeNode.scala:466)\r\n\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1243)\r\n\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\r\n\tat org.apache.spark.sql.catalyst.expressions.BinaryExpression.mapChildren(Expression.scala:653)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:466)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$3(TreeNode.scala:466)\r\n\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\r\n\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\r\n\tat org.apache.spark.sql.catalyst.expressions.UnaryExpression.mapChildren(Expression.scala:533)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:466)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$transformExpressionsDownWithPruning$1(QueryPlan.scala:167)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$1(QueryPlan.scala:208)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:208)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:219)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$3(QueryPlan.scala:224)\r\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\r\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\r\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:224)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$4(QueryPlan.scala:229)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:304)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:229)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsDownWithPruning(QueryPlan.scala:167)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsWithPruning(QueryPlan.scala:138)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveExpressionsWithPruning$1.applyOrElse(AnalysisHelper.scala:245)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveExpressionsWithPruning$1.applyOrElse(AnalysisHelper.scala:244)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$2(AnalysisHelper.scala:170)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:170)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning(AnalysisHelper.scala:99)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning$(AnalysisHelper.scala:96)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveExpressionsWithPruning(AnalysisHelper.scala:244)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveExpressionsWithPruning$(AnalysisHelper.scala:242)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveExpressionsWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions$.apply(Analyzer.scala:2000)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions$.apply(Analyzer.scala:1996)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\r\n\tat scala.collection.IndexedSeqOptimized.foldLeft(IndexedSeqOptimized.scala:60)\r\n\tat scala.collection.IndexedSeqOptimized.foldLeft$(IndexedSeqOptimized.scala:68)\r\n\tat scala.collection.mutable.WrappedArray.foldLeft(WrappedArray.scala:38)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\r\n\tat scala.collection.immutable.List.foreach(List.scala:431)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\r\n\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\r\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\r\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\r\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$1(Dataset.scala:91)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:89)\r\n\tat org.apache.spark.sql.Dataset.withPlan(Dataset.scala:4363)\r\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1541)\r\n\tat org.apache.spark.sql.Dataset.withColumns(Dataset.scala:2782)\r\n\tat org.apache.spark.sql.Dataset.withColumn(Dataset.scala:2721)\r\n\tat sun.reflect.GeneratedMethodAccessor143.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:547)\r\n\tat org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:568)\r\n\tat org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:591)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:688)\r\n\tat org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDurationHelper(Configuration.java:1907)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1867)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1840)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)\r\n\tat org.apache.hadoop.util.ShutdownHookManager$HookEntry.<init>(ShutdownHookManager.java:207)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.addShutdownHook(ShutdownHookManager.java:304)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.install(ShutdownHookManager.scala:181)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks$lzycompute(ShutdownHookManager.scala:50)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks(ShutdownHookManager.scala:48)\r\n\tat org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<init>(ShutdownHookManager.scala:58)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<clinit>(ShutdownHookManager.scala)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:242)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir(SparkFileUtils.scala:103)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir$(SparkFileUtils.scala:102)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:94)\r\n\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:372)\r\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:964)\r\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)\r\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)\r\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nCaused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:467)\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:438)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:515)\r\n\t... 25 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m user_similarity_centered \u001b[38;5;241m=\u001b[39m \u001b[43muser_similarity\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcentered_cosine_similarity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcosine_similarity / (norm(u1.normalized_features, 2) * norm(u2.normalized_features, 2))\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m user_similarity_centered\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Note: This example demonstrates user-user similarity. You can adapt the code for item-item similarity as well.  \u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:5170\u001b[0m, in \u001b[0;36mDataFrame.withColumn\u001b[1;34m(self, colName, col)\u001b[0m\n\u001b[0;32m   5165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, Column):\n\u001b[0;32m   5166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m   5167\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_COLUMN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5168\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(col)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m   5169\u001b[0m     )\n\u001b[1;32m-> 5170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o3480.withColumn.\n: java.lang.RuntimeException: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:735)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:270)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:286)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:978)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:660)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788)\r\n\tat org.apache.spark.sql.catalyst.catalog.InMemoryCatalog.liftedTree1$1(InMemoryCatalog.scala:122)\r\n\tat org.apache.spark.sql.catalyst.catalog.InMemoryCatalog.createDatabase(InMemoryCatalog.scala:119)\r\n\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:159)\r\n\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\r\n\tat org.apache.spark.sql.internal.BaseSessionStateBuilder.$anonfun$catalog$1(BaseSessionStateBuilder.scala:154)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isPersistentFunction(SessionCatalog.scala:1579)\r\n\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.functionExists(V2SessionCatalog.scala:367)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions$$anonfun$apply$20.applyOrElse(Analyzer.scala:2009)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions$$anonfun$apply$20.applyOrElse(Analyzer.scala:2000)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$3(TreeNode.scala:466)\r\n\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)\r\n\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\r\n\tat org.apache.spark.sql.catalyst.expressions.BinaryExpression.mapChildren(Expression.scala:653)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:466)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$3(TreeNode.scala:466)\r\n\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1243)\r\n\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)\r\n\tat org.apache.spark.sql.catalyst.expressions.BinaryExpression.mapChildren(Expression.scala:653)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:466)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$3(TreeNode.scala:466)\r\n\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\r\n\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\r\n\tat org.apache.spark.sql.catalyst.expressions.UnaryExpression.mapChildren(Expression.scala:533)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:466)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$transformExpressionsDownWithPruning$1(QueryPlan.scala:167)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$1(QueryPlan.scala:208)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:208)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:219)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$3(QueryPlan.scala:224)\r\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\r\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\r\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:224)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$4(QueryPlan.scala:229)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:304)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:229)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsDownWithPruning(QueryPlan.scala:167)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsWithPruning(QueryPlan.scala:138)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveExpressionsWithPruning$1.applyOrElse(AnalysisHelper.scala:245)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveExpressionsWithPruning$1.applyOrElse(AnalysisHelper.scala:244)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$2(AnalysisHelper.scala:170)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:170)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning(AnalysisHelper.scala:99)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning$(AnalysisHelper.scala:96)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveExpressionsWithPruning(AnalysisHelper.scala:244)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveExpressionsWithPruning$(AnalysisHelper.scala:242)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveExpressionsWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions$.apply(Analyzer.scala:2000)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions$.apply(Analyzer.scala:1996)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\r\n\tat scala.collection.IndexedSeqOptimized.foldLeft(IndexedSeqOptimized.scala:60)\r\n\tat scala.collection.IndexedSeqOptimized.foldLeft$(IndexedSeqOptimized.scala:68)\r\n\tat scala.collection.mutable.WrappedArray.foldLeft(WrappedArray.scala:38)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\r\n\tat scala.collection.immutable.List.foreach(List.scala:431)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\r\n\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\r\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\r\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\r\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$1(Dataset.scala:91)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:89)\r\n\tat org.apache.spark.sql.Dataset.withPlan(Dataset.scala:4363)\r\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1541)\r\n\tat org.apache.spark.sql.Dataset.withColumns(Dataset.scala:2782)\r\n\tat org.apache.spark.sql.Dataset.withColumn(Dataset.scala:2721)\r\n\tat sun.reflect.GeneratedMethodAccessor143.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:547)\r\n\tat org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:568)\r\n\tat org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:591)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:688)\r\n\tat org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDurationHelper(Configuration.java:1907)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1867)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1840)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)\r\n\tat org.apache.hadoop.util.ShutdownHookManager$HookEntry.<init>(ShutdownHookManager.java:207)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.addShutdownHook(ShutdownHookManager.java:304)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.install(ShutdownHookManager.scala:181)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks$lzycompute(ShutdownHookManager.scala:50)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks(ShutdownHookManager.scala:48)\r\n\tat org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<init>(ShutdownHookManager.scala:58)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<clinit>(ShutdownHookManager.scala)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:242)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir(SparkFileUtils.scala:103)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir$(SparkFileUtils.scala:102)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:94)\r\n\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:372)\r\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:964)\r\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)\r\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)\r\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nCaused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:467)\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:438)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:515)\r\n\t... 25 more\r\n"
     ]
    }
   ],
   "source": [
    "user_similarity_centered = user_similarity.withColumn(\n",
    "    \"centered_cosine_similarity\",\n",
    "    expr(\"cosine_similarity / (norm(u1.normalized_features, 2) * norm(u2.normalized_features, 2))\")\n",
    ")\n",
    " \n",
    "user_similarity_centered.show()\n",
    " \n",
    "# Note: This example demonstrates user-user similarity. You can adapt the code for item-item similarity as well.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bacb5d4-536f-487b-a88f-3ee193c49ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad658b9-7d06-4714-bb59-bf5f0878a274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f20241-0421-4412-addf-2c7873b5aba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b9e2a2-9b92-4bd2-b5fd-c2eb83930505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7fb4c6-678f-4ba2-ba2e-4429d97358c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29a6c09-6700-45f3-b5cf-6c571eadfe32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc5d0e5c-4b93-41d8-a633-400380fcccbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- AccountID: string (nullable = true)\n",
      " |-- Number_Of_Loans_Granted__c: integer (nullable = true)\n",
      " |-- Num_Of_Loans_Paid__c: integer (nullable = true)\n",
      " |-- Purpose_of_Loan__c: string (nullable = true)\n",
      " |-- Total_Repayments__c: integer (nullable = true)\n",
      " |-- Amount: integer (nullable = true)\n",
      " |-- Term_in_Weeks__c: double (nullable = true)\n",
      " |-- Payment_Frequency__c: string (nullable = true)\n",
      " |-- StageName: string (nullable = true)\n",
      " |-- Applicant Age: integer (nullable = true)\n",
      " |-- summary_income: double (nullable = true)\n",
      " |-- summary_income_cv: double (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- loanId: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- LoanIdFormat: integer (nullable = true)\n",
      " |-- prediction: float (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24d2c7c3-8104-4b83-a3d8-2e4c3ece98ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+------+------+-------------------+-----+----------+\n",
      "|LoanIdFormat|loanId|userId|Amount|Total_Repayments__c|count|prediction|\n",
      "+------------+------+------+------+-------------------+-----+----------+\n",
      "|           1|  1447|   833|   200|                 10|    1| 0.9927087|\n",
      "|           1|  1859|  2366|   500|                 10|    1|0.99272466|\n",
      "|           1|  4283|   833|   200|                 10|    1| 0.9927087|\n",
      "|           1|  4283|   833|   200|                 10|    1| 0.9927087|\n",
      "|           1|  6365|  3749|   400|                 10|    1| 0.9927638|\n",
      "|           1| 11509|  3749|  1000|                 10|    1| 0.9927638|\n",
      "|           1| 11799|   148|   250|                 10|    2| 1.9854532|\n",
      "|           1| 18371|  4818|   600|                 10|    2| 1.9854676|\n",
      "|           1| 23404| 12027|   400|                 10|    1|0.99272466|\n",
      "|           1| 30328|  1238|   250|                 10|    3| 2.9783304|\n",
      "|           1| 30328|  1238|   250|                 10|    3| 2.9783304|\n",
      "+------------+------+------+------+-------------------+-----+----------+\n",
      "only showing top 11 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select([\"LoanIdFormat\",\"loanId\",\"userId\",\"Amount\",\"Total_Repayments__c\",\"count\",\"prediction\"]).show(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0147d25-61eb-481f-a2dc-e754f74540cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0|    6|\n",
      "| 0.4780522|    1|\n",
      "| 0.6373373|    1|\n",
      "| 0.6584665|    1|\n",
      "|  0.689326|    1|\n",
      "| 0.7128293|    1|\n",
      "|0.75508547|    1|\n",
      "|0.76943505|    1|\n",
      "|0.77362174|    1|\n",
      "| 0.8119633|    1|\n",
      "|0.81252056|    1|\n",
      "| 0.8148231|    1|\n",
      "|0.83843994|    1|\n",
      "|0.83859515|    1|\n",
      "|0.84813917|    6|\n",
      "|0.86054224|    1|\n",
      "|0.86565226|    1|\n",
      "| 0.8848132|    1|\n",
      "| 0.8869176|    1|\n",
      "| 0.8922921|    2|\n",
      "| 0.9077615|    1|\n",
      "| 0.9114744|    1|\n",
      "| 0.9121581|    1|\n",
      "| 0.9121731|    2|\n",
      "|0.91401196|    1|\n",
      "| 0.9189796|    1|\n",
      "| 0.9232255|   27|\n",
      "|0.92810667|    1|\n",
      "|0.92925423|    1|\n",
      "| 0.9297418|    2|\n",
      "|0.93299097|    4|\n",
      "|0.93397653|    4|\n",
      "| 0.9352826|    5|\n",
      "| 0.9358399|    1|\n",
      "| 0.9369781|    2|\n",
      "|0.93700665|   21|\n",
      "| 0.9409862|    1|\n",
      "|  0.942026|    6|\n",
      "| 0.9465314|    1|\n",
      "| 0.9476901|    1|\n",
      "|  0.949451|    1|\n",
      "| 0.9601713|    1|\n",
      "|0.96408415|    7|\n",
      "|0.97204447|    1|\n",
      "| 0.9905545|    1|\n",
      "|  1.010535|    3|\n",
      "| 1.0361874|    1|\n",
      "| 1.0374606|    1|\n",
      "|  1.047809|    1|\n",
      "|  1.054086|    1|\n",
      "+----------+-----+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.groupBy(predictions.prediction).count().sort(predictions.prediction).show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b1cb23d-bf6b-4cbe-9240-3a6c0dad2815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|        prediction|      LoanIdFormat|\n",
      "+-------+------------------+------------------+\n",
      "|  count|            110762|            110762|\n",
      "|   mean|1.6592763887953046| 4.523500839638143|\n",
      "| stddev|0.8900132734018381|2.7998824460256815|\n",
      "|    min|        0.27527267|                 1|\n",
      "|    max|         7.9435873|                20|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"prediction\",\"LoanIdFormat\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6947ef5d-365a-4f71-a8f9-c865c01e05eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd852bd-f5eb-4095-8b02-f255707397bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4fc2d3e-b55f-485c-a87d-ff790847e567",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol='count', predictionCol='prediction')\n",
    "error = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71839857-cdf9-4dbc-9310-f433c4b95729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for the above mnodel is : 0.020444812351840813\n"
     ]
    }
   ],
   "source": [
    "print(f\"The RMSE for the above mnodel is : {error}\")  # o.463"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e841871-6577-464c-afd2-ef42dc748376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f3d2b7d-9df0-40e8-9653-b67d488fd4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "userRecommends = final_model.recommendForAllUsers(5)\n",
    "loanRecommends = final_model.recommendForAllItems(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61490ce4-2ace-47dd-9d3b-b5b0f541a3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LoanIdFormat: integer (nullable = false)\n",
      " |-- recommendations: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- userId: integer (nullable = true)\n",
      " |    |    |-- rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loanRecommends.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cae2167c-8455-4c19-a013-dd44e4b9d333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------------------------+-------------------------------------------------------+\n",
      "|LoanIdFormat|userId                            |rating                                                 |\n",
      "+------------+----------------------------------+-------------------------------------------------------+\n",
      "|20          |[1832, 24531, 24495, 25243, 24364]|[7.925859, 6.93368, 6.897699, 5.949613, 5.948376]      |\n",
      "|10          |[1832, 24531, 24495, 25243, 24364]|[7.943282, 6.9493465, 6.9234138, 5.962423, 5.9613705]  |\n",
      "|1           |[1832, 24531, 24495, 24364, 25243]|[7.9422646, 6.9486647, 6.925728, 5.9587727, 5.9584146] |\n",
      "|11          |[1832, 24531, 24495, 25243, 24364]|[7.929284, 6.936657, 6.900826, 5.9548006, 5.953773]    |\n",
      "|12          |[1832, 24531, 24495, 24633, 30796]|[7.9482226, 6.9548264, 6.951849, 5.965371, 5.962574]   |\n",
      "|2           |[1832, 24531, 24495, 25243, 24364]|[7.940413, 6.9467936, 6.919386, 5.960266, 5.960021]    |\n",
      "|13          |[1832, 24495, 24531, 24713, 24608]|[5.7865367, 5.0946417, 5.0587287, 4.9884152, 4.972638] |\n",
      "|3           |[1832, 24531, 24495, 24364, 25243]|[7.95235, 6.95837, 6.952184, 5.9646697, 5.963507]      |\n",
      "|4           |[1832, 24531, 24495, 25243, 24364]|[7.9289966, 6.9363832, 6.8998227, 5.9551706, 5.9546113]|\n",
      "|14          |[1832, 24531, 24495, 24364, 25243]|[7.9465656, 6.952481, 6.931186, 5.9631968, 5.962983]   |\n",
      "+------------+----------------------------------+-------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loanRecommends.select([\"LoanIdFormat\",\"recommendations.userId\",\"recommendations.rating\"]).show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf08c18d-dae8-41f4-8595-f5922b0bcbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = false)\n",
      " |-- recommendations: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- LoanIdFormat: integer (nullable = true)\n",
      " |    |    |-- rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userRecommends.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe062ea4-87e7-4f4e-9412-95c267d1d474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+-----------------------------------------------------------+\n",
      "|userId|LoanIdFormat      |rating                                                     |\n",
      "+------+------------------+-----------------------------------------------------------+\n",
      "|1     |[10, 8, 3, 14, 12]|[2.9811091, 2.9807904, 2.980191, 2.9799118, 2.9789734]     |\n",
      "|6     |[3, 7, 12, 6, 8]  |[0.99395484, 0.9936038, 0.99342227, 0.99326104, 0.99238056]|\n",
      "|12    |[3, 7, 12, 6, 8]  |[1.9876392, 1.98745, 1.9870634, 1.9860642, 1.9834268]      |\n",
      "|13    |[3, 12, 7, 6, 8]  |[0.99418116, 0.99351645, 0.9934004, 0.9933137, 0.9933035]  |\n",
      "|16    |[3, 12, 8, 7, 14] |[0.99412996, 0.9937981, 0.99337596, 0.99325854, 0.99317884]|\n",
      "|22    |[3, 12, 7, 6, 8]  |[0.99409443, 0.99357677, 0.99351203, 0.99326074, 0.9929124]|\n",
      "|26    |[3, 8, 12, 14, 10]|[0.9939673, 0.9935692, 0.99345833, 0.9933308, 0.9930572]   |\n",
      "|27    |[3, 12, 7, 8, 6]  |[0.99407005, 0.9935667, 0.99326724, 0.99326193, 0.9931031] |\n",
      "|28    |[3, 8, 14, 10, 12]|[0.99346983, 0.99346447, 0.9932265, 0.9930822, 0.9929975]  |\n",
      "|31    |[7, 12, 3, 6, 8]  |[1.9866652, 1.9866084, 1.9858973, 1.98365, 1.9793448]      |\n",
      "+------+------------------+-----------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userRecommends.select([\"userId\",\"recommendations.LoanIdFormat\",\"recommendations.rating\"]).show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c43a8fb-3e0f-436e-ba38-8adf5efba30e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "506f48ec-bf35-468a-9836-17ac00c01137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------------------------------------------------------------------------------\n",
      " LoanIdFormat    | 10                                                                                                \n",
      " recommendations | [{1832, 7.943282}, {24531, 6.9493465}, {24495, 6.9234138}, {25243, 5.962423}, {24364, 5.9613705}] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "loanRecommends.filter(loanRecommends.LoanIdFormat == 10 ).show(vertical=True,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2bc25c-5a85-45e2-b89a-d75d65a70040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f7708c-9e0d-4e94-921d-4d9354ddfff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3746986-f722-4a7c-9b38-eb0b29f58b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd2003f-d376-41b2-a93e-ac9ececa4a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033322bf-b7b3-4ef5-9ab7-feb8249ba3ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b546cb9-ecdd-4922-a710-513e94c0472e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9bcaa4-1bdc-41c7-9243-2ea48dbad534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6363316-327c-4857-9ca8-f5faead059c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5e2e17-f927-47ec-90d1-3e99bf69ccf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66323d0a-fcbd-40d0-a13e-6b9449a77f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e719f90-aee0-453a-87d5-df0e82ae507d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d656cc-fa74-43fc-bcd2-9a73ff7c11ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33def82-a07b-4e44-8f8e-560f0a15ffcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650b4b08-6081-4dc9-9e5f-b2e34a2008bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c7c001-9cd5-4715-9d50-720d5ba66e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc93743b-4f9b-445e-ad88-359faef40b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For example, 30% of items will be masked\n",
    "# percent_items_to_mask = 0.3 \n",
    "# # Determine the number of items to mask for each user\n",
    "# df_rec_final = df_rec_filtered.withColumn(\"num_items_to_mask\", (col(\"num_items\") * percent_items_to_mask).cast(\"int\"))\n",
    "# # Masks items for each user\n",
    "# df_rec_final = df_rec_final.withColumn(\"item_rank\", rank().over(user_window))\n",
    "\n",
    "# # Create a StringIndexer model to index the user ID column\n",
    "# indexer_user = StringIndexer(inputCol='userId', outputCol='userIndex').setHandleInvalid(\"keep\")\n",
    "# indexer_item = StringIndexer(inputCol='itemId', outputCol='itemIndex').setHandleInvalid(\"keep\")\n",
    "\n",
    "# # Fit the indexer model to the data and transform the DataFrame\n",
    "# df_rec_final = indexer_user.fit(df_rec_final).transform(df_rec_final)\n",
    "# df_rec_final = indexer_item.fit(df_rec_final).transform(df_rec_final)\n",
    "\n",
    "# # Convert the userIndex column to integer type\n",
    "# df_rec_final = df_rec_final.withColumn('userIndex', df_rec_final['userIndex'].cast('integer'))\\\n",
    "#                .withColumn('itemIndex', df_rec_final['itemIndex'].cast('integer'))\n",
    "\n",
    "# train_df_rec = df_rec_final.filter(col(\"item_rank\") > col(\"num_items_to_mask\"))\n",
    "# test_df_rec = df_rec_final.filter(col(\"item_rank\") <= col(\"num_items_to_mask\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1b2843f-61d6-42bf-8730-2ceb384e382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, validation_df = ratings_df.randomSplit([.8,.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "042c7928-94b7-4743-a232-392aa20173f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the ALS model\n",
    "als = ALS(userCol='userId', itemCol='movieId', ratingCol='rating',\n",
    "          coldStartStrategy='drop', nonnegative=True)\n",
    "\n",
    "param_grid = ParamGridBuilder()\\\n",
    "             .addGrid(als.rank, [1, 4, 10, 20, 30])\\\n",
    "             .addGrid(als.maxIter, [10 ,12,18,20])\\\n",
    "             .addGrid(als.regParam, [0.001, 0.01, .05, .15])\\\n",
    "             .build()\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating', predictionCol='prediction')\n",
    "\n",
    "cv = CrossValidator(\n",
    "        estimator=als,\n",
    "        estimatorParamMaps=param_grid,\n",
    "        evaluator=evaluator,\n",
    "        numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e683bcc-6fcb-447a-bed9-b2657075346c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank:  1\n",
      "MaxIter:  20\n",
      "RegParam:  0.01\n"
     ]
    }
   ],
   "source": [
    "model = cv.fit(training_df)\n",
    "\n",
    "best_model = model.bestModel\n",
    "print('rank: ', best_model.rank)\n",
    "print('MaxIter: ', best_model._java_obj.parent().getMaxIter())\n",
    "print('RegParam: ', best_model._java_obj.parent().getRegParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f273cace-8604-4535-9a9d-e0d75b8787ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 0.8744795298421134\n"
     ]
    }
   ],
   "source": [
    "# Train the model using the training data\n",
    "als_using_best_params = ALS(maxIter = best_model._java_obj.parent().getMaxIter(),regParam = best_model._java_obj.parent().getRegParam(),rank = best_model.rank,\n",
    "        userCol='userId', itemCol='movieId', ratingCol='rating',\n",
    "          coldStartStrategy='drop', nonnegative=True)\n",
    "model = als_using_best_params.fit(training_df)\n",
    "\n",
    "# Generate predictions on the test data\n",
    "predictions = best_model.transform(validation_df)\n",
    "predictions = predictions.withColumn(\"prediction\", expr(\"CASE WHEN prediction < 1 THEN 1 WHEN prediction > 5 THEN 5 ELSE prediction END\"))\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating', predictionCol='prediction')\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df974746-f89f-4696-9598-83a1a9aa1c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+----------+\n",
      "|userId|movieId|rating| timestamp|prediction|\n",
      "+------+-------+------+----------+----------+\n",
      "|   322|   1580|   3.5|1217676294|  3.068567|\n",
      "|   593|   1580|   1.5|1181007882|  3.054487|\n",
      "|   597|   1580|   3.0| 941558308| 3.8594012|\n",
      "|   597|   2366|   5.0| 941729029|  3.914689|\n",
      "|   368|   2366|   4.0| 975828914| 2.9883285|\n",
      "|   368|   3918|   2.0| 971273835| 3.6173298|\n",
      "|   115|   1645|   4.0| 957648208| 3.6923604|\n",
      "|   385|   1238|   3.0| 865026050|  4.028213|\n",
      "|   183|   1580|   4.0| 992331667|  3.525297|\n",
      "|   436|    471|   3.0| 833530187| 3.5021195|\n",
      "+------+-------+------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8dd0e209-ecb8-4a55-a2b4-224ffea506f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------------------+----------+\n",
      "|userId|title                           |prediction|\n",
      "+------+--------------------------------+----------+\n",
      "|322   |Men in Black (a.k.a. MIB) (1997)|3.068567  |\n",
      "|593   |Men in Black (a.k.a. MIB) (1997)|3.054487  |\n",
      "|597   |Men in Black (a.k.a. MIB) (1997)|3.8594012 |\n",
      "|597   |King Kong (1933)                |3.914689  |\n",
      "|368   |King Kong (1933)                |2.9883285 |\n",
      "|368   |Hellbound: Hellraiser II (1988) |3.6173298 |\n",
      "|115   |The Devil's Advocate (1997)     |3.6923604 |\n",
      "|385   |Local Hero (1983)               |4.028213  |\n",
      "|183   |Men in Black (a.k.a. MIB) (1997)|3.525297  |\n",
      "|436   |Hudsucker Proxy, The (1994)     |3.5021195 |\n",
      "+------+--------------------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.join(movies_df,\"movieId\").select(\"userId\",\"title\",\"prediction\").show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60252fc1-09fc-4f04-b534-3d4871e93536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+----------+\n",
      "|userId|movieId|rating| timestamp|prediction|\n",
      "+------+-------+------+----------+----------+\n",
      "|   322|   1580|   3.5|1217676294|  3.068567|\n",
      "|   593|   1580|   1.5|1181007882|  3.054487|\n",
      "|   597|   1580|   3.0| 941558308| 3.8594012|\n",
      "|   597|   2366|   5.0| 941729029|  3.914689|\n",
      "|   368|   2366|   4.0| 975828914| 2.9883285|\n",
      "|   368|   3918|   2.0| 971273835| 3.6173298|\n",
      "|   115|   1645|   4.0| 957648208| 3.6923604|\n",
      "|   385|   1238|   3.0| 865026050|  4.028213|\n",
      "|   183|   1580|   4.0| 992331667|  3.525297|\n",
      "|   436|    471|   3.0| 833530187| 3.5021195|\n",
      "+------+-------+------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e18c55-1601-4b17-b6dc-57800a0c12bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178b10e9-b7c9-4bba-9ecc-d440a0121994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5d99235-2358-4b4f-a372-f45062cb2fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "userRecommends = model.recommendForAllUsers(5)\n",
    "movieRecommends = model.recommendForAllItems(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "290e070b-ca79-4728-a718-b54a114c28f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------------------------------------------------------------------------------+\n",
      "|userId|recommendations                                                                                |\n",
      "+------+-----------------------------------------------------------------------------------------------+\n",
      "|1     |[{6835, 10.826822}, {5746, 10.826822}, {5181, 10.826822}, {7899, 9.74414}, {5764, 9.74414}]    |\n",
      "|2     |[{6835, 8.613483}, {5746, 8.613483}, {5181, 8.613483}, {7899, 7.752135}, {5764, 7.752135}]     |\n",
      "|3     |[{6835, 4.9506826}, {5746, 4.9506826}, {5181, 4.9506826}, {7899, 4.4556146}, {5764, 4.4556146}]|\n",
      "|4     |[{6835, 8.38581}, {5746, 8.38581}, {5181, 8.38581}, {7899, 7.547229}, {5764, 7.547229}]        |\n",
      "|5     |[{6835, 8.882423}, {5746, 8.882423}, {5181, 8.882423}, {7899, 7.994181}, {5764, 7.994181}]     |\n",
      "|6     |[{6835, 9.649032}, {5746, 9.649032}, {5181, 9.649032}, {7899, 8.684129}, {5764, 8.684129}]     |\n",
      "|7     |[{6835, 8.051511}, {5746, 8.051511}, {5181, 8.051511}, {7899, 7.246359}, {5764, 7.246359}]     |\n",
      "|8     |[{6835, 9.043954}, {5746, 9.043954}, {5181, 9.043954}, {7899, 8.139559}, {5764, 8.139559}]     |\n",
      "|9     |[{6835, 8.963494}, {5746, 8.963494}, {5181, 8.963494}, {7899, 8.067144}, {5764, 8.067144}]     |\n",
      "|10    |[{6835, 8.018471}, {5746, 8.018471}, {5181, 8.018471}, {7899, 7.216624}, {5764, 7.216624}]     |\n",
      "+------+-----------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userRecommends.select([\"userId\",\"recommendations\"]).show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d13528e6-295b-44d0-8804-9eea5c3dbd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+\n",
      "|movieId|userID               |\n",
      "+-------+---------------------+\n",
      "|1      |[53, 43, 276, 12, 93]|\n",
      "|12     |[53, 43, 276, 12, 93]|\n",
      "|13     |[53, 43, 276, 12, 93]|\n",
      "|22     |[53, 43, 276, 12, 93]|\n",
      "|26     |[53, 43, 276, 12, 93]|\n",
      "|27     |[53, 43, 276, 12, 93]|\n",
      "|28     |[53, 43, 276, 12, 93]|\n",
      "|31     |[53, 43, 276, 12, 93]|\n",
      "|34     |[53, 43, 276, 12, 93]|\n",
      "|44     |[53, 43, 276, 12, 93]|\n",
      "+-------+---------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movieRecommends.select([\"movieId\",\"recommendations.userId\"]).show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5992195-37e4-4f03-87c2-a4dd1d23e4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04152596-1f0a-46dc-8ba1-88706c954011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b24de-e439-49fc-94ba-bb61c3a3ccde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc06d9c-3815-423f-8cb2-f29d74509b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710503d3-3bb8-469f-b911-61420cf73037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf80f9f-a69e-4621-8806-9c566fc2760a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6507a2-9e7d-4773-bcf8-944b9a32e994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9662120d-cf62-4625-a356-c54e17f02e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064b797b-516a-4c67-bb91-b410c5d2f269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af855611-69bc-472c-9e7e-f7bccdd6da2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d2fab2-1ad0-4960-bd5d-33e86e815e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d46a85e-678a-494f-a1da-ada6ceeacfa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8136dba-9546-4250-95cc-572f5396258c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f674f51-ee08-4f17-85ae-e45a113145eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acb6099-abb6-4cff-9e49-3eeb104578c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcba036f-b1e9-461b-8242-00098fae6275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba217e9-9090-4a73-9485-71c92c28419a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22529ea9-b51f-4a38-b3ee-d40eb5c77d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2909cdce-0035-4a3d-9689-ab4c7872bb70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ae7ac8-4a44-433e-9543-3116b5500f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import mean\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml import Pipeline\n",
    " \n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"ALSExample\").getOrCreate()\n",
    " \n",
    "# Sample data for user-item interactions\n",
    "data = [(0, 0, 4.0), (0, 1, 2.0), (1, 1, 3.0), (1, 2, 4.0), (2, 0, 1.0), (2, 2, 5.0)]\n",
    " \n",
    "# Create a DataFrame with columns 'user', 'item', and 'rating'\n",
    "df = spark.createDataFrame(data, [\"user\", \"item\", \"rating\"])\n",
    " \n",
    "# Split the data into training and testing sets\n",
    "(training, test) = df.randomSplit([0.8, 0.2])\n",
    " \n",
    "# Build the ALS model\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"user\", itemCol=\"item\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "model = als.fit(training)\n",
    " \n",
    "# Generate predictions on the test set\n",
    "predictions = model.transform(test)\n",
    " \n",
    "# Evaluate the model using Root Mean Squared Error (RMSE)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) = \" + str(rmse))\n",
    " \n",
    "# Calculate cosine similarity between users using Normalizer and dot product\n",
    "user_normalizer = Normalizer(inputCol=\"features\", outputCol=\"normalized_features\", p=2.0)\n",
    "user_normalized = user_normalizer.transform(model.userFactors)\n",
    " \n",
    "user_features = user_normalized.select(\"id\", \"normalized_features\").withColumnRenamed(\"id\", \"user_id\")\n",
    " \n",
    "user_similarity = user_features.alias(\"u1\").crossJoin(user_features.alias(\"u2\"))\n",
    " \n",
    "user_similarity = user_similarity.withColumn(\n",
    "    \"cosine_similarity\",\n",
    "    col(\"u1.normalized_features\").dot(col(\"u2.normalized_features\"))\n",
    ")\n",
    " \n",
    "# Centered cosine similarity\n",
    "avg_rating = df.select(mean(\"rating\")).collect()[0][0]\n",
    " \n",
    "user_similarity_centered = user_similarity.withColumn(\n",
    "    \"centered_cosine_similarity\",\n",
    "    col(\"cosine_similarity\") / (col(\"u1.normalized_features\").norm(2) * col(\"u2.normalized_features\").norm(2))\n",
    ")\n",
    " \n",
    "user_similarity_centered.show()\n",
    " \n",
    "# Note: This example demonstrates user-user similarity. You can adapt the code for item-item similarity as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2866ce89-53b6-4825-b53d-9391a4866636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f83e0bf-1fe3-4625-88a1-26fb9eb94606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acabc90-3214-497e-872b-5c64f60f2d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c5689f-94af-462a-b715-11e8476d126e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bae612-7516-4974-b713-c1dfc13ee362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece6e4b3-79ad-420c-8c39-e840866f075c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
